{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaan Desai\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Conv3D,MaxPooling3D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core dataframe processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resize_data(x_train,y_train):\n",
    "    \"\"\"\n",
    "        set all input charge densities to have same dimension.. Trim down to z=320\n",
    "    \"\"\"\n",
    "    N = x_train.shape[0]\n",
    "    new_xtrain = []\n",
    "    new_ytrain = []\n",
    "    #Nx = x_train.shape[1]\n",
    "    #Ny = x_train.shape[2]\n",
    "    zsize = 200\n",
    "    #print(x_train[0][0,0,0,0])\n",
    "    #x_train_M = np.empty((N,Nx,Ny,zsize))\n",
    "    for i in range(N):\n",
    "        #condition to check for empty matrices\n",
    "        if x_train[i].any():\n",
    "            new_xtrain.append(x_train[i][0,:,:,:zsize])\n",
    "            new_ytrain.append(y_train[i])\n",
    "    return new_xtrain,new_ytrain\n",
    "\n",
    "def train_test(df_charge,train_size):\n",
    "    \"\"\" \n",
    "        Get training and test data \n",
    "        * Train_size input is fraction of total data size\n",
    "    \"\"\"   \n",
    "    \n",
    "    msk = np.random.rand(len(df_charge)) < train_size\n",
    "    charge_data = df_charge['charge_data'].values\n",
    "    mag_data = df_charge['charge_class'].values\n",
    "    x_train = charge_data[msk].copy()\n",
    "    y_train = mag_data[msk].copy()\n",
    "    x_test = charge_data[~msk].copy()\n",
    "    y_test = mag_data[~msk].copy()\n",
    "    x_train,y_train = resize_data(x_train,y_train)\n",
    "    x_test,y_test = resize_data(x_test,y_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "#create channels for the image\n",
    "#only run this once, otherwise you'll keep appending new values at the end\n",
    "def channels(x_t):\n",
    "    \"\"\"\n",
    "    create channels for the image - currently creates 2 channels (positive and negative)\n",
    "    only run this once, otherwise you'll keep appending new values at the end\n",
    "    \"\"\"\n",
    "    newvec = []\n",
    "    for i in range(x_t.shape[0]):\n",
    "        xt1 = np.copy(x_t[i])\n",
    "        xt2 = np.copy(x_t[i])\n",
    "        xt1[xt1<0] = 0\n",
    "        xt2[xt2>0] = 0\n",
    "        old_shape = list(xt1.shape)\n",
    "        old_shape.append(2)\n",
    "        new_shape = tuple(old_shape)\n",
    "        newtemp = np.zeros(new_shape)\n",
    "        newtemp[:,:,:,0] = xt1\n",
    "        newtemp[:,:,:,1] = xt2\n",
    "        newvec.append(newtemp)\n",
    "    return newvec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read input from splitter\n",
    "df_charge=pd.read_pickle('chgdf_new_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train test split\n",
    "train_size = 0.80\n",
    "x_train, y_train, x_test, y_test = train_test(df_charge,train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#replicate the charge matrix \n",
    "#dimx and dimy define the scale at which you want to replicate thus 1,1 means return input\n",
    "#dimx and dimy need to be integers!\n",
    "def matmul(mat,dimx,dimy):\n",
    "    \"\"\"\n",
    "    replicate the charge matrix in the x and y directions by scaling factor of dimx,dimy\n",
    "    dimx,dimy need to be integers\n",
    "    \"\"\"\n",
    "    xrep = np.shape(mat)[0]\n",
    "    yrep = np.shape(mat)[1]\n",
    "    zrep = np.shape(mat)[2]\n",
    "    #assumes only 56 and 60 base dimensions\n",
    "    if(yrep==56):\n",
    "        temp = np.zeros(((dimx+1)*xrep,(dimx+1)*yrep,1*zrep))\n",
    "        #iterate for the integer multiple\n",
    "        for i in range(int(dimx)):\n",
    "            for j in range(int(dimy)):\n",
    "                temp[i*xrep:(i+1)*xrep,yrep*j:(j+1)*yrep,:] = mat\n",
    "        ret_mat = temp[:(dimx*60),:(dimx*60),:]\n",
    "    else:\n",
    "        temp = np.zeros(((dimx)*xrep,(dimx)*yrep,1*zrep))\n",
    "        #iterate for the integer multiple\n",
    "        for i in range(int(dimx)):\n",
    "            for j in range(int(dimy)):\n",
    "                temp[i*xrep:(i+1)*xrep,yrep*j:(j+1)*yrep,:] = mat\n",
    "        ret_mat = temp\n",
    "    return ret_mat        \n",
    "\n",
    "new_xtrain = []\n",
    "new_xtest = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    new_xtrain.append(matmul(x_train[i],2,2))\n",
    "for i in range(x_test.shape[0]):\n",
    "    new_xtest.append(matmul(x_test[i],2,2))\n",
    "x_train = np.array(new_xtrain)\n",
    "x_test = np.array(new_xtest)\n",
    "\n",
    "#print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2)\n",
      "(186, 2)\n"
     ]
    }
   ],
   "source": [
    "#call channels which splits this into a positive and negative sparse matrix\n",
    "num_classes = 2\n",
    "\n",
    "x_test = channels(x_test)\n",
    "x_train = channels(x_train)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# keras likes one hot encoding instead of class names\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 120, 120, 200, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 61, 61, 141, 1)    432001    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 30, 30, 70, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 16, 56, 3)     10128     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 8, 8, 28, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 10754     \n",
      "=================================================================\n",
      "Total params: 452,883\n",
      "Trainable params: 452,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an empty network model\n",
    "model = Sequential()\n",
    "\n",
    "# --- input layer ---\n",
    "#no padding #width,height,depth,channels\n",
    "model.add(Conv3D(1, kernel_size=(60,60,60),strides=(1,1,1), activation='relu', input_shape=(120,120,200,2)))\n",
    "# --- max pool ---\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "# # --- next layer ---\n",
    "# # we could double the number of filters as max pool made the \n",
    "# # feature maps much smaller \n",
    "# # just not doing this to improve runtime\n",
    "model.add(Conv3D(3, kernel_size=(15,15,15), activation='relu'))\n",
    "# # --- max pool ---\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "# # flatten for fully connected classification layer\n",
    "model.add(Flatten())\n",
    "# # note that the 2 is the number of classes we have\n",
    "# # the classes are mutually exclusive so softmax is a good choice\n",
    "# # --- fully connected layer ---\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# # --- classification ---\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# prints out a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this does all necessary compiling. In tensorflow this is much quicker than in theano\n",
    "# the setup is our basic categorical crossentropy with stochastic gradient decent\n",
    "# we also specify that we want to evaluate our model in terms of accuracy\n",
    "sgd = SGD(lr=1, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='mean_squared_error',\n",
    "#               optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 186 samples, validate on 45 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# this is now the actual training\n",
    "# in addition to the training data we provide validation data\n",
    "# this data is used to calculate the performance of the model over all the epochs\n",
    "# this is useful to determine when training should stop\n",
    "# in our case we just use it to monitor the evolution of the model over the training epochs\n",
    "# if we use the validation data to determine when to stop the training or which model to save, we \n",
    "# should not use the test data, but a separate validation set. \n",
    "batch_size = 20\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=1,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test, y_test))\n",
    "\n",
    "# # once training is complete, let's see how well we have done\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.694856584072113\n",
      "Test accuracy: 0.42105263471603394\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_test1.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
