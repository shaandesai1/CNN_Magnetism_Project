{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaan Desai\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Conv3D,MaxPooling3D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core dataframe processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_target(y_train):\n",
    "    \"\"\" create ytarget var from magnetic moment values \"\"\"\n",
    "    print(np.mean(y_train))\n",
    "    low_dex = np.where(y_train < 4)[0]\n",
    "    hi_dex = np.where(y_train >= 4)[0]\n",
    "    y_train[low_dex] = 0\n",
    "    y_train[hi_dex] = 1\n",
    "    return y_train\n",
    "\n",
    "def resize_data(x_train):\n",
    "    \"\"\"\n",
    "        set all input charge densities to have same dimension.. Trim down to z=320\n",
    "    \"\"\"\n",
    "    N = x_train.shape[0]\n",
    "    zsize = 320\n",
    "    x_train_M = np.empty((N,60,60,zsize))\n",
    "    for ith, xtr in enumerate(x_train):\n",
    "        x_train_M[ith,:,:,:] = xtr[0,:,:,:zsize]\n",
    "    return x_train_M\n",
    "\n",
    "def train_test(df_charge,train_size):\n",
    "    \"\"\" \n",
    "        Get training and test data \n",
    "        * Train_size input is fraction of total data size\n",
    "    \"\"\"   \n",
    "    N = len(df_charge)\n",
    "    #print(N)\n",
    "    randex = np.random.permutation(np.arange(N))\n",
    "    trN = np.int(np.floor(train_size*N))\n",
    "    print(trN)\n",
    "    charge_data = df_charge['sorted_charge_data'].values\n",
    "    mag_data = df_charge['mag_mom'].values\n",
    "    x_train = charge_data[:trN].copy()\n",
    "    y_train = mag_data[:trN].copy()\n",
    "    x_test = charge_data[trN:].copy()\n",
    "    y_test = mag_data[trN:].copy()\n",
    "    #resize:\n",
    "    print(x_train.shape)\n",
    "    x_train = resize_data(x_train)\n",
    "    print(x_train.shape)\n",
    "    x_test = resize_data(x_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "#create channels for the image\n",
    "#only run this once, otherwise you'll keep appending new values at the end\n",
    "def channels(x_t):\n",
    "    \"\"\"\n",
    "    create channels for the image - currently creates 2 channels (positive and negative)\n",
    "    only run this once, otherwise you'll keep appending new values at the end\n",
    "    \"\"\"\n",
    "    xt1 = np.copy(x_t)\n",
    "    xt2 = np.copy(x_t)\n",
    "    xt1[xt1<0] = 0\n",
    "    xt2[xt2>0] = 0\n",
    "    old_shape = list(xt1.shape)\n",
    "    old_shape.append(2)\n",
    "    new_shape = tuple(old_shape)\n",
    "    newvec = np.zeros(new_shape)\n",
    "    newvec[:,:,:,:,0] = xt1\n",
    "    newvec[:,:,:,:,1] = xt2\n",
    "    return newvec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read input from splitter\n",
    "df_charge=pd.read_pickle('chgdf_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "(43,)\n",
      "(43, 60, 60, 320)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "train_size = 0.70\n",
    "x_train, y_train, x_test, y_test = train_test(df_charge,train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 60, 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainsize = x_train.shape[0]\n",
    "testsize = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "(43,)\n",
      "(43, 60, 60, 320)\n",
      "x_train.shape (43, 60, 60, 320)\n",
      "x_train shape: (43, 60, 60, 120)\n",
      "43 train samples\n",
      "19 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train, x_test, y_test = train_test(df_charge, train_size)\n",
    "print('x_train.shape', x_train.shape)\n",
    "## X_train is of shape n_samples x 28 x 28\n",
    "## for a CNN we want to keep the image shape\n",
    "## need to explicitly tell keras that it is a gray value image\n",
    "## so each image is 60x60x1 not 28x28x3\n",
    "\n",
    "#take a slice out of the volume for training and analysis\n",
    "slice = 120\n",
    "x_train = x_train[:,:,:,:slice]\n",
    "x_test = x_test[:,:,:,:slice]\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, slice)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, slice)\n",
    "input_shape = (img_rows, img_cols, slice)\n",
    "\n",
    "# normalize image values to [0,1]\n",
    "# interestingly the keras example code does not center the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#do not think this applies - not using images\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#replicate the charge matrix \n",
    "#dimx and dimy define the scale at which you want to replicate thus 1,1 means return input\n",
    "#dimx and dimy need to be integers!\n",
    "def matmul(mat,dimx,dimy):\n",
    "    \"\"\"\n",
    "    replicate the charge matrix in the x and y directions by scaling factor of dimx,dimy\n",
    "    dimx,dimy need to be integers\n",
    "    \"\"\"\n",
    "    xrep = np.shape(mat)[0]\n",
    "    yrep = np.shape(mat)[1]\n",
    "    zrep = np.shape(mat)[2]\n",
    "    ret_mat = np.zeros((dimx*xrep,dimy*yrep,1*zrep))\n",
    "    #iterate for the integer multiple\n",
    "    for i in range(int(dimx)):\n",
    "        for j in range(int(dimy)):\n",
    "            ret_mat[i*xrep:(i+1)*xrep,yrep*j:(j+1)*yrep,:] = mat\n",
    "    return ret_mat\n",
    "\n",
    "\n",
    "new_xtrain = []\n",
    "new_xtest = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    new_xtrain.append(matmul(x_train[i,:,:,:],1,1))\n",
    "for i in range(x_test.shape[0]):\n",
    "    new_xtest.append(matmul(x_test[i,:,:,:],1,1))\n",
    "x_train = np.array(new_xtrain)\n",
    "x_test = np.array(new_xtest)\n",
    "\n",
    "#print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape, y_test.shape, x_train.shape, y_train.shape\n",
      "(19, 60, 60, 120, 2) (19,) (43, 60, 60, 120, 2) (43,)\n",
      "3.9977279069767446\n",
      "3.999473684210526\n",
      "(19, 2)\n",
      "(43, 2)\n"
     ]
    }
   ],
   "source": [
    "#call channels which splits this into a positive and negative sparse matrix\n",
    "num_classes = 2\n",
    "\n",
    "x_test = channels(x_test)\n",
    "x_train = channels(x_train)\n",
    "print('x_test.shape, y_test.shape, x_train.shape, y_train.shape')\n",
    "print(x_test.shape, y_test.shape, x_train.shape, y_train.shape)\n",
    "\n",
    "y_train = make_target(y_train)\n",
    "y_test = make_target(y_test)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# keras likes one hot encoding instead of class names\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 56, 56, 116, 3)    753       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 28, 58, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 26, 56, 5)     410       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 13, 13, 28, 5)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 23660)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1514304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,515,597\n",
      "Trainable params: 1,515,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an empty network model\n",
    "model = Sequential()\n",
    "\n",
    "# --- input layer ---\n",
    "#no padding #width,height,depth,channels\n",
    "model.add(Conv3D(3, kernel_size=(5,5,5), activation='relu', input_shape=(60,60,120,2)))\n",
    "# --- max pool ---\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "# --- next layer ---\n",
    "# we could double the number of filters as max pool made the \n",
    "# feature maps much smaller \n",
    "# just not doing this to improve runtime\n",
    "model.add(Conv3D(5, kernel_size=(3,3,3), activation='relu'))\n",
    "# --- max pool ---\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "# flatten for fully connected classification layer\n",
    "model.add(Flatten())\n",
    "# note that the 2 is the number of classes we have\n",
    "# the classes are mutually exclusive so softmax is a good choice\n",
    "# --- fully connected layer ---\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# --- classification ---\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# prints out a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this does all necessary compiling. In tensorflow this is much quicker than in theano\n",
    "# the setup is our basic categorical crossentropy with stochastic gradient decent\n",
    "# we also specify that we want to evaluate our model in terms of accuracy\n",
    "sgd = SGD(lr=1, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='mean_squared_error',\n",
    "#               optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22400623898>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is now the actual training\n",
    "# in addition to the training data we provide validation data\n",
    "# this data is used to calculate the performance of the model over all the epochs\n",
    "# this is useful to determine when training should stop\n",
    "# in our case we just use it to monitor the evolution of the model over the training epochs\n",
    "# if we use the validation data to determine when to stop the training or which model to save, we \n",
    "# should not use the test data, but a separate validation set. \n",
    "batch_size = 20\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=1,\n",
    "            verbose=0,\n",
    "            validation_data=(x_test, y_test),callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "# # once training is complete, let's see how well we have done\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.694856584072113\n",
      "Test accuracy: 0.42105263471603394\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_test1.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-458d5f1afc81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
